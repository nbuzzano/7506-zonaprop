{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV, BayesianRidge, HuberRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#levanto data sets\n",
    "df = pd.read_csv(\"../../machine-learning/cleanedData.csv\")\n",
    "y = df.precio\n",
    "\n",
    "X = pd.read_csv(\"../../machine-learning/xgboost-x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = X.join(y)\n",
    "aux = aux.dropna()\n",
    "aux = aux.sample(n=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aux = aux.precio\n",
    "X_aux = aux.drop(['precio'], axis=1, inplace=False)\n",
    "X_aux.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_aux.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_aux, y_aux, test_size=test_size, random_state=seed)\n",
    "# fit model no training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_features(self,df):\n",
    "\t\tdf['patio'] = df.metrostotales - df.metroscubiertos\n",
    "\t\tdf['ambientes'] = df.habitaciones + df.banos + df.garages\n",
    "\t\t#df['prom_amb'] = df.metroscubiertos / df.ambientes\n",
    "\t\t#df['construccion_density'] = df.metroscubiertos/df.metrostotales\n",
    "\t\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(y_test, ids, model):\n",
    "\t\tfinal_pred = y_test\n",
    "\n",
    "#\t\tids = self.df_test['id'].values\n",
    "\t\ttry:\n",
    "\t\t\tos.mkdir('predictions')\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\n",
    "\t\tsubmit = pd.DataFrame({'id':ids,'target':final_pred})\n",
    "\t\tsubmit.to_csv('predictions/submit-'+model+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "\t\tif not start_time:\n",
    "\t\t\tstart_time = datetime.now()\n",
    "\t\t\treturn start_time\n",
    "\t\telif start_time:\n",
    "\t\t\tthour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "\t\t\ttmin, tsec = divmod(temp_sec, 60)\n",
    "\t\t\tprint('Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LassoCV(data):\n",
    "\n",
    "    train,validacion = data\n",
    "    x_tr,y_tr = train\n",
    "    x_val,y_val = validacion\n",
    "    #print(\"El set de train tiene {} filas y {} columnas\".format(x_tr.shape[0],x_tr.shape[1]))\n",
    "    #print(\"El set de validacion tiene {} filas y {} columnas\".format(x_val.shape[0],x_val.shape[1]))\n",
    "\n",
    "    print('Start training LassoCV...')\n",
    "    start_time = timer()\n",
    "\n",
    "    Lasso = LassoCV(\n",
    "        n_alphas=100,\n",
    "        cv=10,\n",
    "        normalize=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    Lasso.fit(x_tr,y_tr)\n",
    "    print(\"The R2 is: {}\".format(Lasso.score(x_tr,y_tr)))\n",
    "    print(\"The alpha choose by CV is:{}\".format(Lasso.alpha_))\n",
    "    timer(start_time)\n",
    "\n",
    "    print(\"Making prediction on validation data\")\n",
    "    y_val = y_val#np.expm1(y_val)\n",
    "    y_val_pred = Lasso.predict(x_val)#np.expm1(Lasso.predict(x_val))\n",
    "    #np.nan_to_num(X) \"replace nan with zero and inf with finite numbers\".\n",
    "    mae = mean_absolute_error(np.nan_to_num(y_val),np.nan_to_num(y_val_pred))\n",
    "\n",
    "    print(\"El mean absolute error de es {}\".format(mae))\n",
    "    print('Saving model into a pickle')\n",
    "\n",
    "    try:\n",
    "        os.mkdir('pickles')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with open('pickles/LassoCV.pkl','wb') as f:\n",
    "        pickle.dump(Lasso, f)\n",
    "            \n",
    "    return y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training LassoCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 is: 0.7416877725912367\n",
      "The alpha choose by CV is:2320.866146031475\n",
      "Time taken: 0 hours 0 minutes and 0.93 seconds.\n",
      "Making prediction on validation data\n",
      "El mean absolute error de es 578807.0385349854\n",
      "Saving model into a pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...................................................................................................................[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "train = X_train, y_train\n",
    "test =  X_test, y_test\n",
    "data = train, test\n",
    "y_val_pred = train_LassoCV(data)\n",
    "\n",
    "ids = y_test.index\n",
    "save_prediction(y_test=y_val_pred, ids=ids, model='Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#COMO TRATA LASSO LAS FEATURES QUE ESTAN ENCODEADAS ?? (ciudad, provincia, tipodepropidedad, etc)\n",
    "#CON DISTINTOS TIPOS DE ENCODING PODRIA MEJORAR LOS RESULTADOS ???\n",
    "#\n",
    "https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#fuentes\n",
    "#\n",
    "https://stackoverflow.com/questions/24233981/how-does-lassocv-in-scikit-learn-partition-data\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py\n",
    "https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much can you trust the selection of alpha?\n",
      "\n",
      "Alpha parameters maximising the generalization score on different\n",
      "subsets of the data:\n",
      "[fold 0] alpha: 3456.25424, score: 0.67086\n",
      "[fold 1] alpha: 2634.46487, score: 0.40059\n",
      "[fold 2] alpha: 5703.98459, score: 0.49294\n",
      "alpha mean: 3931.56790\n",
      "\n",
      "Answer: Not very much since we obtained different alphas for different\n",
      "subsets of the data and moreover, the scores for these alphas differ\n",
      "quite substantially.\n"
     ]
    }
   ],
   "source": [
    "#NESTED CROSS VALIDATION\n",
    "k_fold = KFold(3)\n",
    "alphas = []\n",
    "\n",
    "print(\"How much can you trust the selection of alpha?\")\n",
    "print()\n",
    "print(\"Alpha parameters maximising the generalization score on different\")\n",
    "print(\"subsets of the data:\")\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X_train, y_train)):\n",
    "    lasso_cv = LassoCV(\n",
    "        n_alphas=100,\n",
    "        cv=10,\n",
    "        normalize=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    lasso_cv.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    alphas.append(lasso_cv.alpha_)\n",
    "    \n",
    "    print(\"[fold {0}] alpha: {1:.5f}, score: {2:.5f}\".\n",
    "          format(k, lasso_cv.alpha_, lasso_cv.score(X_train.iloc[test], y_train.iloc[test])))\n",
    "\n",
    "print(\"alpha mean: {0:.5f}\".format(np.mean(alphas)))\n",
    "\n",
    "print()\n",
    "print(\"Answer: Not very much since we obtained different alphas for different\")\n",
    "print(\"subsets of the data and moreover, the scores for these alphas differ\")\n",
    "print(\"quite substantially.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridgeCV(data):\n",
    "\n",
    "    train,validacion = data\n",
    "    x_tr,y_tr = train\n",
    "    x_val,y_val = validacion\n",
    "    #print(\"El set de train tiene {} filas y {} columnas\".format(x_tr.shape[0],x_tr.shape[1]))\n",
    "    #print(\"El set de validacion tiene {} filas y {} columnas\".format(x_val.shape[0],x_val.shape[1]))\n",
    "\n",
    "    print('Start training RidgeCV...')\n",
    "    start_time = timer()\n",
    "\n",
    "    ridge = RidgeCV(\n",
    "        normalize=True,\n",
    "        alphas=[0.0000999],\n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    ridge.fit(x_tr,y_tr)\n",
    "    print(\"The R2 is: {}\".format(ridge.score(x_tr,y_tr)))\n",
    "    print(\"The alpha choose by CV is:{}\".format(ridge.alpha_))\n",
    "    timer(start_time)\n",
    "\n",
    "    print(\"Making prediction on validation data\")\n",
    "    y_val = y_val#np.expm1(y_val)\n",
    "    y_val_pred = ridge.predict(x_val)#np.expm1(ridge.predict(x_val))\n",
    "    #np.nan_to_num(X) \"replace nan with zero and inf with finite numbers\".\n",
    "    mae = mean_absolute_error(np.nan_to_num(y_val),np.nan_to_num(y_val_pred))\n",
    "\n",
    "    print(\"El mean absolute error de es {}\".format(mae))\n",
    "    print('Saving model into a pickle')\n",
    "\n",
    "    try:\n",
    "        os.mkdir('pickles')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with open('pickles/RidgeCV.pkl','wb') as f:\n",
    "        pickle.dump(ridge, f)\n",
    "            \n",
    "    return y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training RidgeCV...\n",
      "The R2 is: 0.780026576429594\n",
      "The alpha choose by CV is:9.99e-05\n",
      "Time taken: 0 hours 0 minutes and 0.11 seconds.\n",
      "Making prediction on validation data\n",
      "El mean absolute error de es 690595.3366460925\n",
      "Saving model into a pickle\n"
     ]
    }
   ],
   "source": [
    "train = X_train, y_train\n",
    "test =  X_test, y_test\n",
    "data = train, test\n",
    "y_val_pred = train_ridgeCV(data)\n",
    "\n",
    "ids = y_test.index\n",
    "save_prediction(y_test=y_val_pred, ids=ids, model='Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much can you trust the selection of alpha?\n",
      "\n",
      "Alpha parameters maximising the generalization score on different\n",
      "subsets of the data:\n",
      "[fold 0] alpha: 0.00010, score: 0.63716\n",
      "[fold 1] alpha: 0.00010, score: 0.24311\n",
      "[fold 2] alpha: 0.00010, score: 0.60722\n",
      "alpha mean: 0.00010\n",
      "score mean: 0.49583\n",
      "\n",
      "Answer: More reliable than Lasso experiment since we obtained same alphas for different\n",
      "subsets of the data BUT the scores for these alphas differ\n",
      "quite substantially.\n"
     ]
    }
   ],
   "source": [
    "#NESTED CROSS VALIDATION\n",
    "k_fold = KFold(3)\n",
    "alphas = []\n",
    "scores = []\n",
    "\n",
    "print(\"How much can you trust the selection of alpha?\")\n",
    "print()\n",
    "print(\"Alpha parameters maximising the generalization score on different\")\n",
    "print(\"subsets of the data:\")\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X_train, y_train)):\n",
    "    ridge = RidgeCV(\n",
    "        normalize=True,\n",
    "        alphas=[0.0000999],\n",
    "        cv=10\n",
    "    )\n",
    "    ridge.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    alphas.append(ridge.alpha_)\n",
    "    \n",
    "    score = ridge.score(X_train.iloc[test], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\"[fold {0}] alpha: {1:.5f}, score: {2:.5f}\".\n",
    "          format(k, ridge.alpha_, score))\n",
    "\n",
    "print(\"alpha mean: {0:.5f}\".format(np.mean(alphas)))\n",
    "print(\"score mean: {0:.5f}\".format(np.mean(scores)))\n",
    "\n",
    "print()\n",
    "print(\"Answer: More reliable than Lasso experiment since we obtained same alphas for different\")\n",
    "print(\"subsets of the data BUT the scores for these alphas differ\")\n",
    "print(\"quite substantially.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elasticNetCV(data):\n",
    "\n",
    "    train,validacion = data\n",
    "    x_tr,y_tr = train\n",
    "    x_val,y_val = validacion\n",
    "    #print(\"El set de train tiene {} filas y {} columnas\".format(x_tr.shape[0],x_tr.shape[1]))\n",
    "    #print(\"El set de validacion tiene {} filas y {} columnas\".format(x_val.shape[0],x_val.shape[1]))\n",
    "\n",
    "    print('Start training enetCV...')\n",
    "    start_time = timer()\n",
    "\n",
    "    enet = ElasticNetCV(\n",
    "        normalize=True,\n",
    "        n_alphas=2000,\n",
    "        max_iter = 2000,\n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    enet.fit(x_tr,y_tr)\n",
    "    print(\"The R2 is: {}\".format(enet.score(x_tr,y_tr)))\n",
    "    print(\"The alpha choose by CV is:{}\".format(enet.alpha_))\n",
    "    timer(start_time)\n",
    "\n",
    "    print(\"Making prediction on validation data\")\n",
    "    y_val = y_val#np.expm1(y_val)\n",
    "    y_val_pred = enet.predict(x_val)#np.expm1(ridge.predict(x_val))\n",
    "    #np.nan_to_num(X) \"replace nan with zero and inf with finite numbers\".\n",
    "    mae = mean_absolute_error(np.nan_to_num(y_val),np.nan_to_num(y_val_pred))\n",
    "\n",
    "    print(\"El mean absolute error de es {}\".format(mae))\n",
    "    print('Saving model into a pickle')\n",
    "\n",
    "    try:\n",
    "        os.mkdir('pickles')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with open('pickles/enetCV.pkl','wb') as f:\n",
    "        pickle.dump(enet, f)\n",
    "            \n",
    "    return y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training enetCV...\n",
      "The R2 is: 0.0002157436852815442\n",
      "The alpha choose by CV is:114.97925311512337\n",
      "Time taken: 0 hours 0 minutes and 10.52 seconds.\n",
      "Making prediction on validation data\n",
      "El mean absolute error de es 1114335.4774411486\n",
      "Saving model into a pickle\n"
     ]
    }
   ],
   "source": [
    "train = X_train, y_train\n",
    "test =  X_test, y_test\n",
    "data = train, test\n",
    "y_val_pred = train_elasticNetCV(data)\n",
    "\n",
    "ids = y_test.index\n",
    "save_prediction(y_test=y_val_pred, ids=ids, model='elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much can you trust the selection of alpha?\n",
      "\n",
      "Alpha parameters maximising the generalization score on different\n",
      "subsets of the data:\n",
      "[fold 0] alpha: 0.00010, score: -0.00289\n",
      "[fold 1] alpha: 0.00010, score: -0.07631\n",
      "[fold 2] alpha: 0.00010, score: -0.04488\n",
      "alpha mean: 0.00010\n",
      "scores mean: -0.04136\n",
      "\n",
      "Answer: More reliable than Lasso experiment since we obtained same alphas for different\n",
      "subsets of the data BUT the scores for these alphas differ quite substantially.\n",
      "\n",
      "Ridge experiment got a higher mean score value\n"
     ]
    }
   ],
   "source": [
    "#NESTED CROSS VALIDATION\n",
    "k_fold = KFold(3)\n",
    "alphas = []\n",
    "scores = []\n",
    "\n",
    "print(\"How much can you trust the selection of alpha?\")\n",
    "print()\n",
    "print(\"Alpha parameters maximising the generalization score on different\")\n",
    "print(\"subsets of the data:\")\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X_train, y_train)):\n",
    "    enet = ElasticNetCV(\n",
    "        normalize=True,\n",
    "        n_alphas=2000,\n",
    "        max_iter = 2000,\n",
    "        cv=10\n",
    "    )\n",
    "    enet.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    alphas.append(ridge.alpha_)\n",
    "    \n",
    "    score = enet.score(X_train.iloc[test], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(\"[fold {0}] alpha: {1:.5f}, score: {2:.5f}\".\n",
    "          format(k, ridge.alpha_, score))\n",
    "\n",
    "print(\"alpha mean: {0:.5f}\".format(np.mean(alphas)))\n",
    "print(\"scores mean: {0:.5f}\".format(np.mean(scores)))\n",
    "\n",
    "print()\n",
    "print(\"Answer: More reliable than Lasso experiment since we obtained same alphas for different\")\n",
    "print(\"subsets of the data BUT the scores for these alphas differ quite substantially.\")\n",
    "print(\"\")\n",
    "print(\"Ridge experiment got a higher mean score value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet  Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'normalize': [True],\n",
    "        'n_alphas': [1000, 2000],\n",
    "        'max_iter': [1000, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ElasticNetCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf = RandomizedSearchCV(clf, param_grid, n_iter=40,\n",
    "                            verbose=2, cv=10,\n",
    "                            scoring='neg_mean_squared_error', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized search..\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=40. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.3s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.4s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.3s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.3s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.4s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.4s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=1000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.6s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.7s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=1000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=1000, total=   4.6s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.3s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=1000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=1000, max_iter=2000, total=   2.2s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   5.1s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.7s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.6s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.8s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   5.0s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   5.1s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.8s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.5s\n",
      "[CV] normalize=True, n_alphas=2000, max_iter=2000 ....................\n",
      "[CV] ..... normalize=True, n_alphas=2000, max_iter=2000, total=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized search time: 141.1281771659851\n"
     ]
    }
   ],
   "source": [
    "print(\"Randomized search..\")\n",
    "search_time_start = time.time()\n",
    "rs_clf.fit(X_train, y_train)\n",
    "print(\"Randomized search time:\", time.time() - search_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -2943637415972.0703\n",
      "Best params: \n",
      "max_iter: 1000\n",
      "n_alphas: 1000\n",
      "normalize: True\n"
     ]
    }
   ],
   "source": [
    "best_score = rs_clf.best_score_\n",
    "best_params = rs_clf.best_params_\n",
    "\n",
    "print(\"Best score: {}\".format(best_score))\n",
    "print(\"Best params: \")\n",
    "for param_name in sorted(best_params.keys()):\n",
    "    print('%s: %r' % (param_name, best_params[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
